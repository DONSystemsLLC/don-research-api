#!/usr/bin/env python3
"""
Live Single-Cell Analysis with DON Research API
Testing real PBMC3K data to discover biological insights
"""

import requests
import json
import time
from pathlib import Path

# Configuration
BASE_URL = "http://localhost:8080"
TAMU_TOKEN = "tamu_cai_lab_2025_HkRs17sgvbjnQax2KzD1iqYcHWbAs5xvZZ2ApKptWuc"
HEADERS = {"Authorization": f"Bearer {TAMU_TOKEN}"}
DATA_FILE = Path("data/pbmc3k.h5ad")

def print_section(title):
    """Print a formatted section header"""
    print(f"\n{'='*70}")
    print(f"  {title}")
    print(f"{'='*70}\n")

def test_health():
    """Verify API is accessible"""
    print_section("üè• Health Check")
    response = requests.get(f"{BASE_URL}/api/v1/health", headers=HEADERS)
    health = response.json()
    print(f"API Status: {health.get('status', 'unknown')}")
    print(f"DON Stack: {health.get('don_stack', {}).get('mode', 'unknown')}")
    return response.status_code == 200

def load_dataset():
    """Load and compress the PBMC3K dataset"""
    print_section("üìÇ Compressing PBMC3K Dataset")
    
    print(f"Dataset: {DATA_FILE}")
    print(f"Size: {DATA_FILE.stat().st_size / 1024 / 1024:.1f} MB")
    
    # Compress via genomics endpoint
    with open(DATA_FILE, 'rb') as f:
        files = {'file': ('pbmc3k.h5ad', f, 'application/octet-stream')}
        response = requests.post(
            f"{BASE_URL}/api/v1/genomics/compress",
            headers=HEADERS,
            files=files,
            data={'target_dims': 128}
        )
    
    if response.status_code == 200:
        result = response.json()
        print(f"‚úÖ Dataset compressed successfully!")
        print(f"   Original Dimensions: {result.get('input_dimensions', 'N/A'):,}")
        print(f"   Compressed Dimensions: {result.get('output_dimensions', 'N/A')}")
        compression_stats = result.get('compression_stats', {})
        print(f"   Compression Ratio: {compression_stats.get('ratio', 'N/A')}")
        print(f"   Processing Time: {compression_stats.get('processing_time', 'N/A'):.2f}s")
        print(f"   Algorithm: {result.get('algorithm', 'N/A')}")
        return result
    else:
        print(f"‚ùå Failed to compress dataset: {response.status_code}")
        print(response.text[:500])
        return None

def build_vector_database(dataset_info):
    """Test RAG optimization with PBMC data"""
    print_section("üî¨ RAG Optimization")
    
    # Test RAG optimize
    with open(DATA_FILE, 'rb') as f:
        files = {'file': ('pbmc3k.h5ad', f, 'application/octet-stream')}
        response = requests.post(
            f"{BASE_URL}/api/v1/genomics/rag-optimize",
            headers=HEADERS,
            files=files,
            data={
                'target_dims': 256,
                'cluster_mode': 'louvain'
            }
        )
    
    if response.status_code == 200:
        result = response.json()
        print(f"‚úÖ RAG optimization complete!")
        print(f"   Clusters: {result.get('n_clusters', 'N/A')}")
        print(f"   Vector Dimensions: {result.get('vector_dims', 'N/A')}")
        print(f"   Compression: {result.get('compression_ratio', 'N/A')}")
        print(f"   Algorithm: {result.get('algorithm', 'N/A')}")
        return result
    else:
        print(f"‚ùå Failed RAG optimization: {response.status_code}")
        print(response.text[:500])
        return None

def discover_cell_types():
    """Test quantum stabilization for cell type discovery"""
    print_section("üß¨ Quantum Cell Type Stabilization")
    
    # Test different cell type markers via quantum stabilization
    marker_profiles = [
        ("T cells", [1.0, 0.9, 0.8, 0.7, 0.5]),
        ("B cells", [0.9, 1.0, 0.7, 0.6, 0.4]),
        ("NK cells", [0.8, 0.7, 1.0, 0.8, 0.6]),
        ("Monocytes", [0.7, 0.6, 0.8, 1.0, 0.7]),
    ]
    
    discoveries = []
    
    for cell_type, profile in marker_profiles:
        print(f"\nüîç Stabilizing: {cell_type}")
        print(f"   Profile: {profile}")
        
        # Use quantum stabilization
        response = requests.post(
            f"{BASE_URL}/api/v1/quantum/stabilize",
            headers=HEADERS,
            json={
                'vector': profile,
                'alpha': 0.1,
                'cell_type': cell_type.split()[0].lower()
            }
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"   ‚úÖ Stabilized (dim={len(result.get('stabilized_vector', []))})")
            print(f"   Algorithm: {result.get('algorithm', 'N/A')}")
            discoveries.append({
                'cell_type': cell_type,
                'stabilized': result.get('stabilized_vector', [])[:3]  # First 3 dims
            })
        else:
            print(f"   ‚ùå Stabilization failed: {response.status_code}")
            print(f"      {response.text[:200]}")
    
    return discoveries

def search_similar_clusters(query_info):
    """Test Bio module exports for downstream analysis"""
    print_section("üéØ Bio Module - Export Artifacts")
    
    # Use Bio module to export artifacts (async job)
    response = requests.post(
        f"{BASE_URL}/bio/export-artifacts",
        headers=HEADERS,
        data={
            'project_id': 'pbmc3k_analysis',
            'sync': 'true'  # Synchronous for testing
        }
    )
    
    if response.status_code == 200:
        result = response.json()
        print(f"‚úÖ Artifacts exported!")
        print(f"   Status: {result.get('status', 'N/A')}")
        print(f"   Files: {result.get('files', 'N/A')}")
        print(f"   Format: {result.get('format', 'N/A')}")
        return result
    else:
        print(f"‚ùå Export failed: {response.status_code}")
        print(response.text[:500])
        return None

def analyze_markers():
    """Test QAC fitting and application"""
    print_section("üß™ QAC Error Correction")
    
    print("Testing Quantum Adjacency Code on marker profiles...")
    
    # Create sample marker vectors
    marker_vectors = [
        [1.0, 0.9, 0.8, 0.7, 0.6],
        [0.9, 1.0, 0.7, 0.8, 0.5],
        [0.8, 0.7, 1.0, 0.6, 0.7],
        [0.7, 0.8, 0.6, 1.0, 0.9]
    ]
    
    # Step 1: Fit QAC model
    print("\nüîß Fitting QAC model...")
    response = requests.post(
        f"{BASE_URL}/qac/fit",
        headers=HEADERS,
        json={
            'vectors': marker_vectors,
            'alpha': 0.1,
            'project_id': 'pbmc3k_markers'
        }
    )
    
    if response.status_code == 200:
        fit_result = response.json()
        model_id = fit_result.get('model_id', 'N/A')
        print(f"   ‚úÖ QAC model fitted!")
        print(f"   Model ID: {model_id}")
        print(f"   Status: {fit_result.get('status', 'N/A')}")
        
        # Step 2: Apply QAC model
        print("\nüî¨ Applying QAC correction...")
        response = requests.post(
            f"{BASE_URL}/qac/apply",
            headers=HEADERS,
            json={
                'model_id': model_id,
                'vector': [0.85, 0.75, 0.90, 0.70, 0.65]
            }
        )
        
        if response.status_code == 200:
            apply_result = response.json()
            print(f"   ‚úÖ QAC correction applied!")
            print(f"   Original dim: 5")
            print(f"   Corrected dim: {len(apply_result.get('corrected_vector', []))}")
            print(f"   Algorithm: {apply_result.get('algorithm', 'N/A')}")
        else:
            print(f"   ‚ùå Apply failed: {response.status_code}")
    else:
        print(f"   ‚ùå Fit failed: {response.status_code}")
        print(response.text[:200])

def main():
    """Run complete analysis pipeline"""
    print("\n" + "="*70)
    print("  üß¨ DON RESEARCH API - LIVE SINGLE-CELL ANALYSIS")
    print("  Dataset: PBMC3K (Peripheral Blood Mononuclear Cells)")
    print("="*70)
    
    # Step 1: Health check
    if not test_health():
        print("\n‚ùå API not accessible. Is the server running?")
        return
    
    time.sleep(1)
    
    # Step 2: Compress dataset
    dataset_info = load_dataset()
    if not dataset_info:
        print("\n‚ö†Ô∏è  Skipping remaining operations due to compression failure")
        return
    
    time.sleep(2)
    
    # Step 3: RAG optimization
    rag_info = build_vector_database(dataset_info)
    time.sleep(2)
    
    # Step 4: Quantum stabilization
    discoveries = discover_cell_types()
    time.sleep(2)
    
    # Step 5: Bio module export
    export_results = search_similar_clusters(rag_info if rag_info else None)
    time.sleep(2)
    
    # Step 6: QAC error correction
    analyze_markers()
    
    print_section("‚úÖ Analysis Complete")
    print("Summary:")
    print(f"  ‚Ä¢ PBMC3K dataset compressed with DON-GPU")
    print(f"  ‚Ä¢ RAG optimization tested")
    print(f"  ‚Ä¢ Quantum stabilization on {len(discoveries)} cell types")
    print(f"  ‚Ä¢ QAC error correction demonstrated")
    print(f"  ‚Ä¢ Bio module export validated")
    print("\nüéâ DON Stack working with real single-cell data!")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Analysis interrupted by user")
    except Exception as e:
        print(f"\n\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
